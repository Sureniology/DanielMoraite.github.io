![TensorFlow](/images/robo16.jpeg)

# Into the deep space

## Localized Computation

Lately we have witness how Internet-of-Things (IoT) is making our physical environment and infrastructures smarter.  What we also need to know is that IoT is changing the way we perceive computing and communication.  

And since billions of IoT devices will get activated in the upcoming years, we need to consider  better security, lower costs and higher performance applications - and the answer to the problem is: localized computation. 

The hardware is there or almost there(when we talk about specialized microchips) and the software that enables computations on such small devices is very fast emerging from different agile minds. Few of these minds I’ve met at Plumer.ai. 

They’ve put together Larq, which, to quote: >is an open source machine learning library for training Quantized Neural Networks (QNNs) with extremely low precision weights and activations (e.g. 1-bit). Existing Deep Neural Networks tend to be large, slow and power-hungry, prohibiting many applications in resource-constrained environments. Larq is designed to provide an easy to use, composable way to train QNNs (e.g. Binarized Neural Networks) based on the tf.keras interface.

----------------

### Now let's give it a try: 

First things first: pip install plumerai

![TensorFlow](/images/plumerai1.png)

-------------------









----------------
## Coming soon: 

> Just a few random projects: 

* Object Detection - and the story of how I`ve spent quite considerable time to tag objects in a video created by me.
* OpenCV, etc. - playing with dogs photos is the best. 

----------------
----------------
